"""
Clash Config Merger Tool
Extract proxy nodes from multiple source yaml files, filter, rename, group by country, and generate unified config
"""

import sys
import os

# Avoid shadowing the standard PyYAML library with the local 'yaml' directory
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir in sys.path:
    sys.path.remove(current_dir)

import yaml
import base64
import json
import socket
from urllib.parse import urlparse, unquote
from typing import Optional

# GeoIP database support
try:
    import geoip2.database
    GEOIP_AVAILABLE = True
except ImportError:
    GEOIP_AVAILABLE = False
    print("Warning: geoip2 not installed. Run: pip install geoip2")

class SubscriptionParser:
    """Parse various subscription formats to Clash config"""
    
    @staticmethod
    def decode_base64(content: str) -> str:
        """Safely decode Base64"""
        content = content.strip().replace('-', '+').replace('_', '/')
        missing_padding = len(content) % 4
        if missing_padding:
            content += '=' * (4 - missing_padding)
        try:
            return base64.b64decode(content).decode('utf-8')
        except:
            return ""

    @staticmethod
    def parse_vmess(vmess_url: str) -> Optional[dict]:
        """Parse vmess:// link"""
        try:
            b64 = vmess_url[8:]
            json_str = SubscriptionParser.decode_base64(b64)
            if not json_str: return None
            v = json.loads(json_str)
            
            proxy = {
                "name": v.get("ps", "vmess"),
                "type": "vmess",
                "server": v.get("add"),
                "port": int(v.get("port")),
                "uuid": v.get("id"),
                "alterId": int(v.get("aid", 0)),
                "cipher": "auto",
                "udp": True
            }
            
            if v.get("net") == "ws":
                proxy["network"] = "ws"
                ws_opts = {"path": v.get("path", "/")}
                if v.get("host"):
                    ws_opts["headers"] = {"Host": v.get("host")}
                proxy["ws-opts"] = ws_opts
                
            if v.get("tls") == "tls":
                proxy["tls"] = True
                if v.get("sni"):
                    proxy["servername"] = v.get("sni")
                    
            return proxy
        except Exception:
            return None

    @staticmethod
    def parse_ss(ss_url: str) -> Optional[dict]:
        """Parse ss:// link"""
        try:
            # ss://base64(method:password)@server:port#remark
            # OR ss://base64(method:password@server:port)#remark
            
            if '#' in ss_url:
                main, remark = ss_url[5:].split('#', 1)
                remark = unquote(remark)
            else:
                main = ss_url[5:]
                remark = "ss"
            
            if '@' in main:
                # Format 1: base64(user:pass)@host:port
                user_pass_b64, host_port = main.split('@', 1)
                user_pass = SubscriptionParser.decode_base64(user_pass_b64)
                if ':' not in user_pass: return None
                method, password = user_pass.split(':', 1)
                
                if ':' not in host_port: return None
                server, port = host_port.rsplit(':', 1)
            else:
                # Format 2: base64(method:password@host:port)
                decoded = SubscriptionParser.decode_base64(main)
                if '@' not in decoded: return None
                user_pass, host_port = decoded.split('@', 1)
                if ':' not in user_pass: return None
                method, password = user_pass.split(':', 1)
                if ':' not in host_port: return None
                server, port = host_port.rsplit(':', 1)

            return {
                "name": remark,
                "type": "ss",
                "server": server,
                "port": int(port),
                "cipher": method,
                "password": password,
                "udp": True
            }
        except Exception:
            return None

    @staticmethod
    def parse_trojan(trojan_url: str) -> Optional[dict]:
        """Parse trojan:// link"""
        try:
            # trojan://password@host:port?arg=val#remark
            if '#' in trojan_url:
                main, remark = trojan_url[9:].split('#', 1)
                remark = unquote(remark)
            else:
                main = trojan_url[9:]
                remark = "trojan"
            
            if '?' in main:
                main, query = main.split('?', 1)
            else:
                query = ""
                
            if '@' not in main: return None
            password, host_port = main.split('@', 1)
            if ':' not in host_port: return None
            server, port = host_port.rsplit(':', 1)
            
            proxy = {
                "name": remark,
                "type": "trojan",
                "server": server,
                "port": int(port),
                "password": password,
                "udp": True,
                "skip-cert-verify": True
            }
            
            # Parse query (sni, etc)
            if query:
                params = {}
                for pair in query.split('&'):
                    if '=' in pair:
                        k, v = pair.split('=', 1)
                        params[k] = v
                
                if 'sni' in params:
                    proxy['sni'] = params['sni']
                if 'allowInsecure' in params:
                     proxy['skip-cert-verify'] = (params['allowInsecure'] == '1')
            
            return proxy
        except Exception:
            return None

    @staticmethod
    def parse_vless(vless_url: str) -> Optional[dict]:
        """Parse vless:// link"""
        try:
            # vless://uuid@host:port?args#remark
            if '#' in vless_url:
                main, remark = vless_url[8:].split('#', 1)
                remark = unquote(remark)
            else:
                main = vless_url[8:]
                remark = "vless"
            
            if '?' in main:
                main, query = main.split('?', 1)
            else:
                query = ""
                
            if '@' not in main: return None
            uuid, host_port = main.split('@', 1)
            if ':' not in host_port: return None
            server, port = host_port.rsplit(':', 1)
            
            proxy = {
                "name": remark,
                "type": "vless",
                "server": server,
                "port": int(port),
                "uuid": uuid,
                "udp": True,
                "cipher": "auto"
            }
            
            # Parse query
            params = {}
            if query:
                for pair in query.split('&'):
                    if '=' in pair:
                        k, v = pair.split('=', 1)
                        params[k] = v
            
            # Network / Stream Settings
            network = params.get("type", "tcp")
            proxy["network"] = network
            
            if network == "ws":
                ws_opts = {}
                if "path" in params: ws_opts["path"] = unquote(params["path"])
                if "host" in params: ws_opts["headers"] = {"Host": unquote(params["host"])}
                proxy["ws-opts"] = ws_opts
            elif network == "grpc":
                grpc_opts = {}
                if "serviceName" in params: grpc_opts["grpc-service-name"] = unquote(params["serviceName"])
                proxy["grpc-opts"] = grpc_opts
            
            # Security / TLS / Reality
            security = params.get("security", "")
            if security == "tls":
                proxy["tls"] = True
                if "sni" in params: proxy["servername"] = params["sni"]
                if "fp" in params: proxy["client-fingerprint"] = params["fp"]
                if "flow" in params: proxy["flow"] = params["flow"]
            elif security == "reality":
                proxy["tls"] = True
                proxy["flow"] = params.get("flow", "xtls-rprx-vision")
                if "sni" in params: proxy["servername"] = params["sni"]
                if "fp" in params: proxy["client-fingerprint"] = params["fp"]
                
                reality_opts = {}
                if "pbk" in params: reality_opts["public-key"] = params["pbk"]
                if "sid" in params: reality_opts["short-id"] = params["sid"]
                if "spx" in params: reality_opts["spider-x"] = params["spx"]
                proxy["reality-opts"] = reality_opts
            
            return proxy
        except Exception:
            return None

    @staticmethod
    def parse_ssr(ssr_url: str) -> Optional[dict]:
        """Parse ssr:// link"""
        try:
            b64 = ssr_url[6:]
            decoded = SubscriptionParser.decode_base64(b64)
            
            # server:port:protocol:method:obfs:password_base64/?params
            if '/?' in decoded:
                main, query = decoded.split('/?', 1)
            else:
                main = decoded
                query = ""
                
            parts = main.split(':')
            if len(parts) != 6: return None
            
            server = parts[0]
            port = int(parts[1])
            protocol = parts[2]
            method = parts[3]
            obfs = parts[4]
            password = SubscriptionParser.decode_base64(parts[5])
            
            proxy = {
                "name": "ssr", # temporary
                "type": "ssr",
                "server": server,
                "port": port,
                "cipher": method,
                "password": password,
                "protocol": protocol,
                "obfs": obfs,
                "udp": True
            }
            
            if query:
                params = {}
                for pair in query.split('&'):
                    if '=' in pair:
                        k, v = pair.split('=', 1)
                        params[k] = v # values are base64 encoded usually? SSR query params are weird.
                        
                if 'remarks' in params:
                    proxy['name'] = SubscriptionParser.decode_base64(params['remarks'])
                if 'obfsparam' in params:
                    proxy['obfs-param'] = SubscriptionParser.decode_base64(params['obfsparam'])
                if 'protoparam' in params:
                    proxy['protocol-param'] = SubscriptionParser.decode_base64(params['protoparam'])
                    
            return proxy
        except Exception:
            return None

    @staticmethod
    def parse_hysteria2(hy2_url: str) -> Optional[dict]:
        """Parse hysteria2:// link"""
        try:
            # hysteria2://password@host:port?params#remark
            if '#' in hy2_url:
                main, remark = hy2_url[12:].split('#', 1)
                remark = unquote(remark)
            else:
                main = hy2_url[12:]
                remark = "hy2"
            
            if '?' in main:
                main, query = main.split('?', 1)
            else:
                query = ""
                
            if '@' not in main: return None
            password, host_port = main.split('@', 1)
            
            # Host/Port parsing (handle IPv6)
            if ']:' in host_port: 
                server, port = host_port.rsplit(':', 1)
                server = server.replace('[', '').replace(']', '')
            elif ':' in host_port:
                server, port = host_port.rsplit(':', 1)
            else:
                return None
                
            proxy = {
                "name": remark,
                "type": "hysteria2",
                "server": server,
                "port": int(port),
                "password": password,
                "udp": True,
                "obfs": "none" # Default?
            }
            
            if query:
                params = {}
                for pair in query.split('&'):
                    if '=' in pair:
                        k, v = pair.split('=', 1)
                        params[k] = v
                
                if 'sni' in params: proxy['sni'] = params['sni']
                if 'insecure' in params: proxy['skip-cert-verify'] = (params['insecure'] == '1')
                if 'obfs' in params: proxy['obfs'] = params['obfs']
                if 'obfs-password' in params: proxy['obfs-password'] = params['obfs-password']
            
            return proxy
        except Exception:
            return None

    @staticmethod
    def parse_content(content: str) -> dict:
        """Try to parse content"""
        # 1. Try to parse as YAML directly
        try:
            data = yaml.safe_load(content)
            if isinstance(data, dict) and 'proxies' in data:
                return data
        except:
            pass
            
        # 2. Try Base64 decode
        try:
            decoded = SubscriptionParser.decode_base64(content)
            if 'proxies:' in decoded:
                 # Decoded content is YAML
                 return yaml.safe_load(decoded) or {}
        except:
            decoded = content # Assume it might be plain text link list
            
        # 3. Parse link list
        proxies = []
        lines = decoded.splitlines()
        for line in lines:
            line = line.strip()
            if not line: continue
            
            p = None
            if line.startswith('vmess://'):
                p = SubscriptionParser.parse_vmess(line)
            elif line.startswith('ss://'):
                p = SubscriptionParser.parse_ss(line)
            elif line.startswith('trojan://'):
                p = SubscriptionParser.parse_trojan(line)
            elif line.startswith('vless://'):
                p = SubscriptionParser.parse_vless(line)
            elif line.startswith('ssr://'):
                p = SubscriptionParser.parse_ssr(line)
            elif line.startswith('hysteria2://') or line.startswith('hy2://'):
                p = SubscriptionParser.parse_hysteria2(line)
            elif line.startswith('{') and line.endswith('}'):
                # Try to parse JSON format node (Clash Meta/Hy2 etc may return JSON objects directly)
                try:
                    import json
                    p = json.loads(line)
                    if isinstance(p, dict) and 'name' in p and 'type' in p:
                        proxies.append(p)
                except:
                    pass
                continue
                
            if p: proxies.append(p)
            
        if proxies:
            return {"proxies": proxies}
            
        return {}


# Restore sys.path for normal use (if necessary)
sys.path.insert(0, current_dir)

import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass


# ==================== ProxyFilter ====================

class ProxyFilter:
    """Proxy node filter - filter out invalid info nodes"""
    
    INVALID_KEYWORDS = [
        'å‰©ä½™æµé‡', 'å¥—é¤åˆ°æœŸ', 'è·ç¦»ä¸‹æ¬¡é‡ç½®', 'å»ºè®®', 'å®˜ç½‘', 'æœªåˆ°æœŸ',
        'å‰©ä½™', 'åˆ°æœŸ', 'é‡ç½®'
    ]
    
    @staticmethod
    def is_valid_proxy(proxy: dict) -> bool:
        """Check if proxy node is valid (not an info node)"""
        if not proxy or 'name' not in proxy:
            return False
        name = proxy['name']
        for keyword in ProxyFilter.INVALID_KEYWORDS:
            if keyword in name:
                return False
        return True
    
    @staticmethod
    def filter_proxies(proxies: List[dict]) -> List[dict]:
        """Filter invalid proxy nodes, keep only valid ones"""
        if not proxies:
            return []
        return [p for p in proxies if ProxyFilter.is_valid_proxy(p)]


# ==================== NameTransformer ====================

class NameTransformer:
    """Node name transformer - unify node name format to: Flag Provider NodeName"""
    
    # Source filename to prefix mapping
    SOURCE_PREFIX_MAP = {
        'å®å¯æ¢¦': 'å®å¯æ¢¦',
        'æµé‡å…‰æœºåœº': 'æµé‡å¤š',
        'æ·˜æ°”å…”': 'æ·˜æ°”å…”',
        'é£è§è§å…¬ç›Šæœºåœº': 'é£è§è§',
        'é­”æˆ’': 'é­”æˆ’'
    }
    
    # All flag emojis list (for removal)
    FLAG_EMOJIS = [
        'ğŸ‡­ğŸ‡°', 'ğŸ‡¹ğŸ‡¼', 'ğŸ‡¯ğŸ‡µ', 'ğŸ‡ºğŸ‡¸', 'ğŸ‡¸ğŸ‡¬', 'ğŸ‡°ğŸ‡·', 'ğŸ‡¬ğŸ‡§', 'ğŸ‡©ğŸ‡ª', 'ğŸ‡¨ğŸ‡¦', 'ğŸ‡¦ğŸ‡º',
        'ğŸ‡«ğŸ‡·', 'ğŸ‡·ğŸ‡º', 'ğŸ‡®ğŸ‡³', 'ğŸ‡³ğŸ‡±', 'ğŸ‡¹ğŸ‡·', 'ğŸ‡¦ğŸ‡¶', 'ğŸ‡²ğŸ‡¾', 'ğŸ‡ªğŸ‡¸', 'ğŸ‡»ğŸ‡³', 'ğŸ‡ºğŸ‡¦',
        'ğŸ‡²ğŸ‡©', 'ğŸ‡³ğŸ‡¬', 'ğŸ‡§ğŸ‡·', 'ğŸ‡®ğŸ‡¹', 'ğŸ‡µğŸ‡±', 'ğŸ‡¨ğŸ‡­', 'ğŸ‡¦ğŸ‡¹', 'ğŸ‡§ğŸ‡ª', 'ğŸ‡¸ğŸ‡ª', 'ğŸ‡³ğŸ‡´',
        'ğŸ‡©ğŸ‡°', 'ğŸ‡«ğŸ‡®', 'ğŸ‡®ğŸ‡ª', 'ğŸ‡µğŸ‡¹', 'ğŸ‡¬ğŸ‡·', 'ğŸ‡¨ğŸ‡¿', 'ğŸ‡­ğŸ‡º', 'ğŸ‡·ğŸ‡´', 'ğŸ‡§ğŸ‡¬', 'ğŸ‡­ğŸ‡·',
        'ğŸ‡¸ğŸ‡°', 'ğŸ‡¸ğŸ‡®', 'ğŸ‡±ğŸ‡¹', 'ğŸ‡±ğŸ‡»', 'ğŸ‡ªğŸ‡ª', 'ğŸ‡®ğŸ‡±', 'ğŸ‡¦ğŸ‡ª', 'ğŸ‡¸ğŸ‡¦', 'ğŸ‡¶ğŸ‡¦', 'ğŸ‡°ğŸ‡¼',
        'ğŸ‡´ğŸ‡²', 'ğŸ‡§ğŸ‡­', 'ğŸ‡¯ğŸ‡´', 'ğŸ‡±ğŸ‡§', 'ğŸ‡ªğŸ‡¬', 'ğŸ‡¿ğŸ‡¦', 'ğŸ‡°ğŸ‡ª', 'ğŸ‡³ğŸ‡¿', 'ğŸ‡µğŸ‡­', 'ğŸ‡¹ğŸ‡­',
        'ğŸ‡®ğŸ‡©', 'ğŸ‡µğŸ‡°', 'ğŸ‡§ğŸ‡©', 'ğŸ‡±ğŸ‡°', 'ğŸ‡³ğŸ‡µ', 'ğŸ‡²ğŸ‡²', 'ğŸ‡°ğŸ‡­', 'ğŸ‡±ğŸ‡¦', 'ğŸ‡²ğŸ‡³', 'ğŸ‡°ğŸ‡¿',
        'ğŸ‡ºğŸ‡¿', 'ğŸ‡¦ğŸ‡¿', 'ğŸ‡¬ğŸ‡ª', 'ğŸ‡¦ğŸ‡²', 'ğŸ‡¨ğŸ‡¾', 'ğŸ‡²ğŸ‡¹', 'ğŸ‡®ğŸ‡¸', 'ğŸ‡±ğŸ‡º', 'ğŸ‡²ğŸ‡¨', 'ğŸ‡¦ğŸ‡©',
        'ğŸ‡±ğŸ‡®', 'ğŸ‡¸ğŸ‡²', 'ğŸ‡»ğŸ‡¦', 'ğŸ‡²ğŸ‡½', 'ğŸ‡¦ğŸ‡·', 'ğŸ‡¨ğŸ‡±', 'ğŸ‡¨ğŸ‡´', 'ğŸ‡µğŸ‡ª', 'ğŸ‡»ğŸ‡ª', 'ğŸ‡ªğŸ‡¨',
        'ğŸ‡§ğŸ‡´', 'ğŸ‡µğŸ‡¾', 'ğŸ‡ºğŸ‡¾', 'ğŸ‡¨ğŸ‡·', 'ğŸ‡µğŸ‡¦', 'ğŸ‡¨ğŸ‡º', 'ğŸ‡©ğŸ‡´', 'ğŸ‡µğŸ‡·', 'ğŸ‡¯ğŸ‡²', 'ğŸ‡­ğŸ‡¹',
        'ğŸ”°', 'ğŸŒ', 'ğŸŒ', 'ğŸŒ', 'ğŸ³ï¸'
    ]
    
    # Country identification patterns: Flag -> keyword list
    COUNTRY_FLAG_MAP = {
        'ğŸ‡­ğŸ‡°': ['HK', 'Hong Kong', 'é¦™æ¸¯', 'Hongkong'],
        'ğŸ‡¹ğŸ‡¼': ['TW', 'Taiwan', 'å°æ¹¾', 'Taipei'],
        'ğŸ‡¯ğŸ‡µ': ['JP', 'Japan', 'æ—¥æœ¬', 'Tokyo', 'Osaka'],
        'ğŸ‡ºğŸ‡¸': ['US', 'United States', 'ç¾å›½', 'America', 'USA', 'Los Angeles', 'Seattle', 'San Jose'],
        'ğŸ‡¸ğŸ‡¬': ['SG', 'Singapore', 'æ–°åŠ å¡'],
        'ğŸ‡°ğŸ‡·': ['KR', 'Korea', 'éŸ©å›½', 'Seoul'],
        'ğŸ‡¬ğŸ‡§': ['GB', 'UK', 'United Kingdom', 'è‹±å›½', 'England', 'London'],
        'ğŸ‡©ğŸ‡ª': ['DE', 'Germany', 'å¾·å›½', 'Frankfurt'],
        'ğŸ‡¨ğŸ‡¦': ['CA', 'Canada', 'åŠ æ‹¿å¤§', 'Toronto', 'Vancouver'],
        'ğŸ‡¦ğŸ‡º': ['AU', 'Australia', 'æ¾³å¤§åˆ©äºš', 'æ¾³æ´²', 'Sydney'],
        'ğŸ‡«ğŸ‡·': ['FR', 'France', 'æ³•å›½', 'Paris'],
        'ğŸ‡·ğŸ‡º': ['RU', 'Russia', 'ä¿„ç½—æ–¯', 'Moscow'],
        'ğŸ‡®ğŸ‡³': ['IN', 'India', 'å°åº¦'],
        'ğŸ‡³ğŸ‡±': ['NL', 'Netherlands', 'è·å…°', 'Amsterdam'],
        'ğŸ‡¹ğŸ‡·': ['TR', 'Turkey', 'åœŸè€³å…¶', 'Istanbul'],
        'ğŸ‡¦ğŸ‡¶': ['Antarctica', 'å—æ'],
        'ğŸ‡²ğŸ‡¾': ['MY', 'Malaysia', 'é©¬æ¥è¥¿äºš'],
        'ğŸ‡ªğŸ‡¸': ['ES', 'Spain', 'è¥¿ç­ç‰™'],
        'ğŸ‡»ğŸ‡³': ['VN', 'Vietnam', 'è¶Šå—'],
        'ğŸ‡ºğŸ‡¦': ['UA', 'Ukraine', 'ä¹Œå…‹å…°'],
        'ğŸ‡²ğŸ‡©': ['MD', 'Moldova', 'æ‘©å°”å¤šç“¦'],
        'ğŸ‡³ğŸ‡¬': ['NG', 'Nigeria', 'å°¼æ—¥åˆ©äºš'],
        'ğŸ‡§ğŸ‡·': ['BR', 'Brazil', 'å·´è¥¿'],
        'ğŸ‡®ğŸ‡¹': ['IT', 'Italy', 'æ„å¤§åˆ©'],
        'ğŸ‡µğŸ‡±': ['PL', 'Poland', 'æ³¢å…°'],
        'ğŸ‡¨ğŸ‡­': ['CH', 'Switzerland', 'ç‘å£«'],
        'ğŸ‡¦ğŸ‡¹': ['AT', 'Austria', 'å¥¥åœ°åˆ©'],
        'ğŸ‡§ğŸ‡ª': ['BE', 'Belgium', 'æ¯”åˆ©æ—¶'],
        'ğŸ‡¸ğŸ‡ª': ['SE', 'Sweden', 'ç‘å…¸'],
        'ğŸ‡³ğŸ‡´': ['NO', 'Norway', 'æŒªå¨'],
        'ğŸ‡©ğŸ‡°': ['DK', 'Denmark', 'ä¸¹éº¦'],
        'ğŸ‡«ğŸ‡®': ['FI', 'Finland', 'èŠ¬å…°'],
        'ğŸ‡®ğŸ‡ª': ['IE', 'Ireland', 'çˆ±å°”å…°'],
        'ğŸ‡µğŸ‡¹': ['PT', 'Portugal', 'è‘¡è„ç‰™'],
        'ğŸ‡¬ğŸ‡·': ['GR', 'Greece', 'å¸Œè…Š'],
        'ğŸ‡®ğŸ‡±': ['IL', 'Israel', 'ä»¥è‰²åˆ—'],
        'ğŸ‡¦ğŸ‡ª': ['AE', 'UAE', 'é˜¿è”é…‹', 'Dubai'],
        'ğŸ‡¿ğŸ‡¦': ['ZA', 'South Africa', 'å—é'],
        'ğŸ‡³ğŸ‡¿': ['NZ', 'New Zealand', 'æ–°è¥¿å…°'],
        'ğŸ‡µğŸ‡­': ['PH', 'Philippines', 'è²å¾‹å®¾'],
        'ğŸ‡¹ğŸ‡­': ['TH', 'Thailand', 'æ³°å›½'],
        'ğŸ‡®ğŸ‡©': ['ID', 'Indonesia', 'å°å°¼', 'å°åº¦å°¼è¥¿äºš'],
        'ğŸ‡µğŸ‡°': ['PK', 'Pakistan', 'å·´åŸºæ–¯å¦'],
        'ğŸ‡²ğŸ‡½': ['MX', 'Mexico', 'å¢¨è¥¿å“¥'],
        'ğŸ‡¦ğŸ‡·': ['AR', 'Argentina', 'é˜¿æ ¹å»·'],
    }
    
    @staticmethod
    def remove_flags(name: str) -> str:
        """Remove all flag emojis from node name"""
        result = name
        for flag in NameTransformer.FLAG_EMOJIS:
            result = result.replace(flag, '')
        # Clean up extra spaces
        result = ' '.join(result.split())
        return result.strip()
    
    @staticmethod
    def identify_flag(name: str, server: str = None) -> str:
        """Identify country flag based on node name
        Priority: 1. Flag emoji at the START of name  2. Any flag emoji in name  3. Keyword matching  4. GeoIP lookup  5. Default flag
        """
        # Priority 1: Check if name STARTS with a country flag emoji (most reliable)
        for flag in NameTransformer.FLAG_EMOJIS:
            if name.startswith(flag) and flag != 'ğŸ”°' and flag != 'ğŸŒ' and flag != 'ğŸŒ' and flag != 'ğŸŒ' and flag != 'ğŸ³ï¸':
                return flag
        
        # Priority 2: Check if name contains a country flag emoji anywhere
        for flag in NameTransformer.FLAG_EMOJIS:
            if flag in name and flag != 'ğŸ”°' and flag != 'ğŸŒ' and flag != 'ğŸŒ' and flag != 'ğŸŒ' and flag != 'ğŸ³ï¸':
                return flag
        
        # Priority 3: Try to identify by keywords
        import re
        name_upper = name.upper()
        for flag, patterns in NameTransformer.COUNTRY_FLAG_MAP.items():
            for pattern in patterns:
                # Check if pattern contains Chinese characters
                has_chinese = any('\u4e00' <= c <= '\u9fff' for c in pattern)
                if has_chinese:
                    # For Chinese patterns, simple contains is fine
                    if pattern in name:
                        return flag
                elif len(pattern) <= 3:
                    # For short English patterns, require word boundary
                    pattern_upper = pattern.upper()
                    if re.search(r'(?<![A-Z])' + re.escape(pattern_upper) + r'(?![A-Z])', name_upper):
                        return flag
                else:
                    # For longer English patterns, simple contains is fine
                    if pattern.upper() in name_upper:
                        return flag
        
        # Priority 4: GeoIP lookup (if server address provided)
        if server and GEOIP_AVAILABLE:
            geoip = GeoIPLookup.get_instance()
            flag = geoip.get_flag(server)
            if flag:
                return flag
        
        # Priority 5: Return default flag (unknown)
        return 'ğŸ”°'
    
    @staticmethod
    def transform_name(proxy: dict, source_name: str) -> dict:
        """Unify node name format to: Flag Provider NodeName"""
        if not proxy or 'name' not in proxy:
            return proxy
        
        prefix = NameTransformer.SOURCE_PREFIX_MAP.get(source_name, source_name)
        original_name = proxy['name']
        server = proxy.get('server', '')  # Get server for GeoIP lookup
        
        # 1. Identify flag first (before removal)
        flag = NameTransformer.identify_flag(original_name, server)
        
        # 2. Remove existing flags
        clean_name = NameTransformer.remove_flags(original_name)
        
        # 3. Replace [ipv6] with ipv6
        if '[ipv6]' in clean_name:
            clean_name = clean_name.replace('[ipv6]', 'ipv6')
        
        # 4. Check if provider prefix already exists to avoid duplication
        has_prefix = False
        for known_prefix in NameTransformer.SOURCE_PREFIX_MAP.values():
            if clean_name.startswith(known_prefix + ' ') or clean_name.startswith(known_prefix + '-'):
                has_prefix = True
                break
        
        # 5. Combine new name: Flag Provider NodeName
        if has_prefix:
            new_name = f"{flag} {clean_name}"
        else:
            new_name = f"{flag} {prefix} {clean_name}"
        
        # Create new proxy dict to avoid modifying original object
        new_proxy = proxy.copy()
        new_proxy['name'] = new_name
        return new_proxy
    
    @staticmethod
    def transform_proxies(proxies: List[dict], source_name: str) -> List[dict]:
        """Batch transform proxy node names"""
        return [NameTransformer.transform_name(p, source_name) for p in proxies]


# ==================== GeoIPLookup ====================

class GeoIPLookup:
    """GeoIP lookup using MaxMind GeoLite2 database"""
    
    # ISO country code to flag emoji mapping
    COUNTRY_CODE_TO_FLAG = {
        'HK': 'ğŸ‡­ğŸ‡°', 'TW': 'ğŸ‡¹ğŸ‡¼', 'JP': 'ğŸ‡¯ğŸ‡µ', 'US': 'ğŸ‡ºğŸ‡¸', 'SG': 'ğŸ‡¸ğŸ‡¬',
        'KR': 'ğŸ‡°ğŸ‡·', 'GB': 'ğŸ‡¬ğŸ‡§', 'DE': 'ğŸ‡©ğŸ‡ª', 'CA': 'ğŸ‡¨ğŸ‡¦', 'AU': 'ğŸ‡¦ğŸ‡º',
        'FR': 'ğŸ‡«ğŸ‡·', 'RU': 'ğŸ‡·ğŸ‡º', 'IN': 'ğŸ‡®ğŸ‡³', 'NL': 'ğŸ‡³ğŸ‡±', 'TR': 'ğŸ‡¹ğŸ‡·',
        'AQ': 'ğŸ‡¦ğŸ‡¶', 'MY': 'ğŸ‡²ğŸ‡¾', 'ES': 'ğŸ‡ªğŸ‡¸', 'VN': 'ğŸ‡»ğŸ‡³', 'UA': 'ğŸ‡ºğŸ‡¦',
        'MD': 'ğŸ‡²ğŸ‡©', 'NG': 'ğŸ‡³ğŸ‡¬', 'BR': 'ğŸ‡§ğŸ‡·', 'IT': 'ğŸ‡®ğŸ‡¹', 'PL': 'ğŸ‡µğŸ‡±',
        'CH': 'ğŸ‡¨ğŸ‡­', 'AT': 'ğŸ‡¦ğŸ‡¹', 'BE': 'ğŸ‡§ğŸ‡ª', 'SE': 'ğŸ‡¸ğŸ‡ª', 'NO': 'ğŸ‡³ğŸ‡´',
        'DK': 'ğŸ‡©ğŸ‡°', 'FI': 'ğŸ‡«ğŸ‡®', 'IE': 'ğŸ‡®ğŸ‡ª', 'PT': 'ğŸ‡µğŸ‡¹', 'GR': 'ğŸ‡¬ğŸ‡·',
        'CZ': 'ğŸ‡¨ğŸ‡¿', 'HU': 'ğŸ‡­ğŸ‡º', 'RO': 'ğŸ‡·ğŸ‡´', 'BG': 'ğŸ‡§ğŸ‡¬', 'HR': 'ğŸ‡­ğŸ‡·',
        'SK': 'ğŸ‡¸ğŸ‡°', 'SI': 'ğŸ‡¸ğŸ‡®', 'LT': 'ğŸ‡±ğŸ‡¹', 'LV': 'ğŸ‡±ğŸ‡»', 'EE': 'ğŸ‡ªğŸ‡ª',
        'IL': 'ğŸ‡®ğŸ‡±', 'AE': 'ğŸ‡¦ğŸ‡ª', 'SA': 'ğŸ‡¸ğŸ‡¦', 'QA': 'ğŸ‡¶ğŸ‡¦', 'KW': 'ğŸ‡°ğŸ‡¼',
        'OM': 'ğŸ‡´ğŸ‡²', 'BH': 'ğŸ‡§ğŸ‡­', 'JO': 'ğŸ‡¯ğŸ‡´', 'LB': 'ğŸ‡±ğŸ‡§', 'EG': 'ğŸ‡ªğŸ‡¬',
        'ZA': 'ğŸ‡¿ğŸ‡¦', 'KE': 'ğŸ‡°ğŸ‡ª', 'NZ': 'ğŸ‡³ğŸ‡¿', 'PH': 'ğŸ‡µğŸ‡­', 'TH': 'ğŸ‡¹ğŸ‡­',
        'ID': 'ğŸ‡®ğŸ‡©', 'PK': 'ğŸ‡µğŸ‡°', 'BD': 'ğŸ‡§ğŸ‡©', 'LK': 'ğŸ‡±ğŸ‡°', 'NP': 'ğŸ‡³ğŸ‡µ',
        'MM': 'ğŸ‡²ğŸ‡²', 'KH': 'ğŸ‡°ğŸ‡­', 'LA': 'ğŸ‡±ğŸ‡¦', 'MN': 'ğŸ‡²ğŸ‡³', 'KZ': 'ğŸ‡°ğŸ‡¿',
        'UZ': 'ğŸ‡ºğŸ‡¿', 'AZ': 'ğŸ‡¦ğŸ‡¿', 'GE': 'ğŸ‡¬ğŸ‡ª', 'AM': 'ğŸ‡¦ğŸ‡²', 'CY': 'ğŸ‡¨ğŸ‡¾',
        'MT': 'ğŸ‡²ğŸ‡¹', 'IS': 'ğŸ‡®ğŸ‡¸', 'LU': 'ğŸ‡±ğŸ‡º', 'MC': 'ğŸ‡²ğŸ‡¨', 'AD': 'ğŸ‡¦ğŸ‡©',
        'LI': 'ğŸ‡±ğŸ‡®', 'SM': 'ğŸ‡¸ğŸ‡²', 'VA': 'ğŸ‡»ğŸ‡¦', 'MX': 'ğŸ‡²ğŸ‡½', 'AR': 'ğŸ‡¦ğŸ‡·',
        'CL': 'ğŸ‡¨ğŸ‡±', 'CO': 'ğŸ‡¨ğŸ‡´', 'PE': 'ğŸ‡µğŸ‡ª', 'VE': 'ğŸ‡»ğŸ‡ª', 'EC': 'ğŸ‡ªğŸ‡¨',
        'BO': 'ğŸ‡§ğŸ‡´', 'PY': 'ğŸ‡µğŸ‡¾', 'UY': 'ğŸ‡ºğŸ‡¾', 'CR': 'ğŸ‡¨ğŸ‡·', 'PA': 'ğŸ‡µğŸ‡¦',
        'CU': 'ğŸ‡¨ğŸ‡º', 'DO': 'ğŸ‡©ğŸ‡´', 'PR': 'ğŸ‡µğŸ‡·', 'JM': 'ğŸ‡¯ğŸ‡²', 'HT': 'ğŸ‡­ğŸ‡¹',
        'CN': 'ğŸ‡¨ğŸ‡³',
    }
    
    # ISO country code to Chinese name mapping
    COUNTRY_CODE_TO_NAME = {
        'HK': 'é¦™æ¸¯', 'TW': 'å°æ¹¾', 'JP': 'æ—¥æœ¬', 'US': 'ç¾å›½', 'SG': 'æ–°åŠ å¡',
        'KR': 'éŸ©å›½', 'GB': 'è‹±å›½', 'DE': 'å¾·å›½', 'CA': 'åŠ æ‹¿å¤§', 'AU': 'æ¾³å¤§åˆ©äºš',
        'FR': 'æ³•å›½', 'RU': 'ä¿„ç½—æ–¯', 'IN': 'å°åº¦', 'NL': 'è·å…°', 'TR': 'åœŸè€³å…¶',
        'AQ': 'å—ææ´²', 'MY': 'é©¬æ¥è¥¿äºš', 'ES': 'è¥¿ç­ç‰™', 'VN': 'è¶Šå—', 'UA': 'ä¹Œå…‹å…°',
        'MD': 'æ‘©å°”å¤šç“¦', 'NG': 'å°¼æ—¥åˆ©äºš', 'BR': 'å·´è¥¿', 'IT': 'æ„å¤§åˆ©', 'PL': 'æ³¢å…°',
        'CH': 'ç‘å£«', 'AT': 'å¥¥åœ°åˆ©', 'BE': 'æ¯”åˆ©æ—¶', 'SE': 'ç‘å…¸', 'NO': 'æŒªå¨',
        'DK': 'ä¸¹éº¦', 'FI': 'èŠ¬å…°', 'IE': 'çˆ±å°”å…°', 'PT': 'è‘¡è„ç‰™', 'GR': 'å¸Œè…Š',
        'CZ': 'æ·å…‹', 'HU': 'åŒˆç‰™åˆ©', 'RO': 'ç½—é©¬å°¼äºš', 'BG': 'ä¿åŠ åˆ©äºš', 'HR': 'å…‹ç½—åœ°äºš',
        'SK': 'æ–¯æ´›ä¼å…‹', 'SI': 'æ–¯æ´›æ–‡å°¼äºš', 'LT': 'ç«‹é™¶å®›', 'LV': 'æ‹‰è„±ç»´äºš', 'EE': 'çˆ±æ²™å°¼äºš',
        'IL': 'ä»¥è‰²åˆ—', 'AE': 'é˜¿è”é…‹', 'SA': 'æ²™ç‰¹', 'QA': 'å¡å¡”å°”', 'KW': 'ç§‘å¨ç‰¹',
        'OM': 'é˜¿æ›¼', 'BH': 'å·´æ—', 'JO': 'çº¦æ—¦', 'LB': 'é»å·´å«©', 'EG': 'åŸƒåŠ',
        'ZA': 'å—é', 'KE': 'è‚¯å°¼äºš', 'NZ': 'æ–°è¥¿å…°', 'PH': 'è²å¾‹å®¾', 'TH': 'æ³°å›½',
        'ID': 'å°å°¼', 'PK': 'å·´åŸºæ–¯å¦', 'BD': 'å­ŸåŠ æ‹‰', 'LK': 'æ–¯é‡Œå…°å¡', 'NP': 'å°¼æ³Šå°”',
        'MM': 'ç¼…ç”¸', 'KH': 'æŸ¬åŸ”å¯¨', 'LA': 'è€æŒ', 'MN': 'è’™å¤', 'KZ': 'å“ˆè¨å…‹æ–¯å¦',
        'UZ': 'ä¹Œå…¹åˆ«å…‹', 'AZ': 'é˜¿å¡æ‹œç–†', 'GE': 'æ ¼é²å‰äºš', 'AM': 'äºšç¾å°¼äºš', 'CY': 'å¡æµ¦è·¯æ–¯',
        'MT': 'é©¬è€³ä»–', 'IS': 'å†°å²›', 'LU': 'å¢æ£®å ¡', 'MC': 'æ‘©çº³å“¥', 'AD': 'å®‰é“å°”',
        'LI': 'åˆ—æ”¯æ•¦å£«ç™»', 'SM': 'åœ£é©¬åŠ›è¯º', 'VA': 'æ¢µè’‚å†ˆ', 'MX': 'å¢¨è¥¿å“¥', 'AR': 'é˜¿æ ¹å»·',
        'CL': 'æ™ºåˆ©', 'CO': 'å“¥ä¼¦æ¯”äºš', 'PE': 'ç§˜é²', 'VE': 'å§”å†…ç‘æ‹‰', 'EC': 'å„ç“œå¤šå°”',
        'BO': 'ç»åˆ©ç»´äºš', 'PY': 'å·´æ‹‰åœ­', 'UY': 'ä¹Œæ‹‰åœ­', 'CR': 'å“¥æ–¯è¾¾é»åŠ ', 'PA': 'å·´æ‹¿é©¬',
        'CU': 'å¤å·´', 'DO': 'å¤šç±³å°¼åŠ ', 'PR': 'æ³¢å¤šé»å„', 'JM': 'ç‰™ä¹°åŠ ', 'HT': 'æµ·åœ°',
        'CN': 'ä¸­å›½',
    }
    
    _instance = None
    _reader = None
    _dns_cache = {}  # Cache DNS lookups
    _geoip_cache = {}  # Cache GeoIP lookups
    
    @classmethod
    def get_instance(cls):
        """Singleton pattern for GeoIP reader"""
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance
    
    def __init__(self):
        self._load_database()
    
    def _load_database(self):
        """Load GeoLite2 database"""
        if not GEOIP_AVAILABLE:
            return
        
        # Try multiple possible database locations
        import os
        base_dir = os.path.dirname(os.path.abspath(__file__))
        possible_paths = [
            os.path.join(base_dir, 'GeoLite2-Country.mmdb'),
            os.path.join(base_dir, 'data', 'GeoLite2-Country.mmdb'),
            '/usr/share/GeoIP/GeoLite2-Country.mmdb',
            '/var/lib/GeoIP/GeoLite2-Country.mmdb',
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                try:
                    self._reader = geoip2.database.Reader(path)
                    print(f"GeoIP database loaded: {path}")
                    return
                except Exception as e:
                    print(f"Warning: Failed to load GeoIP database {path}: {e}")
        
        print("Warning: GeoLite2-Country.mmdb not found. GeoIP lookup disabled.")
        print("Download from: https://dev.maxmind.com/geoip/geolite2-free-geolocation-data")
    
    def resolve_domain(self, domain: str) -> Optional[str]:
        """Resolve domain to IP address with caching"""
        if domain in self._dns_cache:
            return self._dns_cache[domain]
        
        try:
            ip = socket.gethostbyname(domain)
            self._dns_cache[domain] = ip
            return ip
        except socket.gaierror:
            self._dns_cache[domain] = None
            return None
    
    def _lookup_via_api(self, ip: str) -> Optional[str]:
        """Fallback: lookup country code via free APIs
        Priority: ip-api.com -> ipwho.is
        """
        import requests
        
        # Try ip-api.com first (45 req/min, no key needed)
        try:
            resp = requests.get(f"http://ip-api.com/json/{ip}?fields=countryCode", timeout=3)
            if resp.status_code == 200:
                data = resp.json()
                if data.get('countryCode'):
                    return data['countryCode']
        except Exception:
            pass
        
        # Try ipwho.is (unlimited, no key needed)
        try:
            resp = requests.get(f"https://ipwho.is/{ip}?fields=country_code", timeout=3)
            if resp.status_code == 200:
                data = resp.json()
                if data.get('country_code'):
                    return data['country_code']
        except Exception:
            pass
        
        return None
    
    def lookup(self, server: str) -> Optional[str]:
        """Lookup country code for server (IP or domain)
        Returns ISO country code (e.g., 'US', 'JP') or None
        Priority: 1. Local GeoLite2 DB  2. ip-api.com  3. ipwho.is
        """
        # Check cache first
        if server in self._geoip_cache:
            return self._geoip_cache[server]
        
        # Determine if server is IP or domain
        ip = server
        try:
            socket.inet_aton(server)  # Check if valid IPv4
        except socket.error:
            try:
                socket.inet_pton(socket.AF_INET6, server)  # Check if valid IPv6
            except socket.error:
                # It's a domain, resolve it
                ip = self.resolve_domain(server)
                if not ip:
                    self._geoip_cache[server] = None
                    return None
        
        country_code = None
        
        # Priority 1: Try local GeoIP database
        if self._reader:
            try:
                response = self._reader.country(ip)
                country_code = response.country.iso_code
            except Exception:
                pass
        
        # Priority 2 & 3: Fallback to APIs if local DB failed
        if not country_code:
            country_code = self._lookup_via_api(ip)
        
        self._geoip_cache[server] = country_code
        return country_code
    
    def get_country_group(self, server: str) -> Optional[str]:
        """Get country group name (e.g., 'ğŸ‡ºğŸ‡¸ ç¾å›½') for server"""
        country_code = self.lookup(server)
        if not country_code:
            return None
        
        flag = self.COUNTRY_CODE_TO_FLAG.get(country_code, 'ğŸ”°')
        name = self.COUNTRY_CODE_TO_NAME.get(country_code, country_code)
        return f"{flag} {name}"
    
    def get_flag(self, server: str) -> Optional[str]:
        """Get flag emoji for server"""
        country_code = self.lookup(server)
        if not country_code:
            return None
        return self.COUNTRY_CODE_TO_FLAG.get(country_code)


# ==================== CountryGrouper ====================

class CountryGrouper:
    """Group proxy nodes by country/region"""
    
    # Country identification patterns: Group name -> keyword list
    COUNTRY_PATTERNS = {
        'ğŸ‡­ğŸ‡° é¦™æ¸¯': ['ğŸ‡­ğŸ‡°', 'HK', 'Hong Kong', 'é¦™æ¸¯'],
        'ğŸ‡¹ğŸ‡¼ å°æ¹¾': ['ğŸ‡¹ğŸ‡¼', 'TW', 'Taiwan', 'å°æ¹¾', 'Taipei'],
        'ğŸ‡¯ğŸ‡µ æ—¥æœ¬': ['ğŸ‡¯ğŸ‡µ', 'JP', 'Japan', 'æ—¥æœ¬'],
        'ğŸ‡ºğŸ‡¸ ç¾å›½': ['ğŸ‡ºğŸ‡¸', 'US', 'United States', 'ç¾å›½'],
        'ğŸ‡¸ğŸ‡¬ æ–°åŠ å¡': ['ğŸ‡¸ğŸ‡¬', 'SG', 'Singapore', 'æ–°åŠ å¡'],
        'ğŸ‡°ğŸ‡· éŸ©å›½': ['ğŸ‡°ğŸ‡·', 'KR', 'Korea', 'éŸ©å›½'],
        'ğŸ‡¬ğŸ‡§ è‹±å›½': ['ğŸ‡¬ğŸ‡§', 'GB', 'UK', 'United Kingdom', 'è‹±å›½', 'England'],
        'ğŸ‡©ğŸ‡ª å¾·å›½': ['ğŸ‡©ğŸ‡ª', 'DE', 'Germany', 'å¾·å›½'],
        'ğŸ‡¨ğŸ‡¦ åŠ æ‹¿å¤§': ['ğŸ‡¨ğŸ‡¦', 'CA', 'Canada', 'åŠ æ‹¿å¤§'],
        'ğŸ‡¦ğŸ‡º æ¾³å¤§åˆ©äºš': ['ğŸ‡¦ğŸ‡º', 'AU', 'Australia', 'æ¾³å¤§åˆ©äºš', 'æ¾³æ´²'],
        'ğŸ‡«ğŸ‡· æ³•å›½': ['ğŸ‡«ğŸ‡·', 'FR', 'France', 'æ³•å›½'],
        'ğŸ‡·ğŸ‡º ä¿„ç½—æ–¯': ['ğŸ‡·ğŸ‡º', 'RU', 'Russia', 'ä¿„ç½—æ–¯'],
        'ğŸ‡®ğŸ‡³ å°åº¦': ['ğŸ‡®ğŸ‡³', 'IN', 'India', 'å°åº¦'],
        'ğŸ‡³ğŸ‡± è·å…°': ['ğŸ‡³ğŸ‡±', 'NL', 'Netherlands', 'è·å…°'],
        'ğŸ‡¹ğŸ‡· åœŸè€³å…¶': ['ğŸ‡¹ğŸ‡·', 'TR', 'Turkey', 'åœŸè€³å…¶'],
        'ğŸ‡¦ğŸ‡¶ å—ææ´²': ['ğŸ‡¦ğŸ‡¶', 'Antarctica', 'å—æ'],
        'ğŸ‡²ğŸ‡¾ é©¬æ¥è¥¿äºš': ['ğŸ‡²ğŸ‡¾', 'MY', 'Malaysia', 'é©¬æ¥è¥¿äºš'],
        'ğŸ‡ªğŸ‡¸ è¥¿ç­ç‰™': ['ğŸ‡ªğŸ‡¸', 'ES', 'Spain', 'è¥¿ç­ç‰™'],
        'ğŸ‡»ğŸ‡³ è¶Šå—': ['ğŸ‡»ğŸ‡³', 'VN', 'Vietnam', 'è¶Šå—'],
        'ğŸ‡ºğŸ‡¦ ä¹Œå…‹å…°': ['ğŸ‡ºğŸ‡¦', 'UA', 'Ukraine', 'ä¹Œå…‹å…°'],
        'ğŸ‡²ğŸ‡© æ‘©å°”å¤šç“¦': ['ğŸ‡²ğŸ‡©', 'MD', 'Moldova', 'æ‘©å°”å¤šç“¦'],
        'ğŸ‡³ğŸ‡¬ å°¼æ—¥åˆ©äºš': ['ğŸ‡³ğŸ‡¬', 'NG', 'Nigeria', 'å°¼æ—¥åˆ©äºš'],
        'ğŸ‡³ğŸ‡´ æŒªå¨': ['ğŸ‡³ğŸ‡´', 'NO', 'Norway', 'æŒªå¨'],
    }
    
    @staticmethod
    def identify_country(proxy_name: str, proxy_server: str = None) -> str:
        """Identify country/region of proxy node
        Priority: 1. Flag emoji at START of name  2. Any flag emoji in name  3. Keyword matching  4. GeoIP lookup  5. Unknown
        """
        # Priority 1: Check if name STARTS with a flag emoji (most reliable)
        for country, patterns in CountryGrouper.COUNTRY_PATTERNS.items():
            flag = patterns[0]  # First pattern is always the flag emoji
            if proxy_name.startswith(flag):
                return country
        
        # Priority 2: Check for any flag emoji in name
        for country, patterns in CountryGrouper.COUNTRY_PATTERNS.items():
            flag = patterns[0]
            if flag in proxy_name:
                return country
        
        # Priority 3: Try keyword matching
        import re
        for country, patterns in CountryGrouper.COUNTRY_PATTERNS.items():
            for pattern in patterns[1:]:  # Skip the flag emoji
                # Check if pattern contains Chinese characters
                has_chinese = any('\u4e00' <= c <= '\u9fff' for c in pattern)
                if has_chinese:
                    # For Chinese patterns, simple contains is fine
                    if pattern in proxy_name:
                        return country
                elif len(pattern) <= 3:
                    # For short English patterns, require word boundary
                    if re.search(r'(?<![A-Za-z])' + re.escape(pattern) + r'(?![A-Za-z])', proxy_name, re.IGNORECASE):
                        return country
                else:
                    # For longer English patterns, simple contains is fine
                    if pattern.upper() in proxy_name.upper():
                        return country
        
        # Priority 4: GeoIP lookup (if server address provided)
        if proxy_server and GEOIP_AVAILABLE:
            geoip = GeoIPLookup.get_instance()
            country_group = geoip.get_country_group(proxy_server)
            if country_group:
                # Add to COUNTRY_PATTERNS if not exists (for future lookups)
                if country_group not in CountryGrouper.COUNTRY_PATTERNS:
                    # Extract flag from country_group
                    parts = country_group.split(' ', 1)
                    if len(parts) == 2:
                        flag, name = parts
                        CountryGrouper.COUNTRY_PATTERNS[country_group] = [flag, name]
                return country_group
        
        return 'ğŸ”° æœªçŸ¥'
    
    @staticmethod
    def group_by_country(proxies: List[dict]) -> Dict[str, List[str]]:
        """Group proxy nodes by country/region, return {country: [node_name_list]}"""
        groups: Dict[str, List[str]] = {}
        
        for proxy in proxies:
            name = proxy.get('name', '')
            server = proxy.get('server', '')  # Get server address for GeoIP lookup
            country = CountryGrouper.identify_country(name, server)
            
            if country not in groups:
                groups[country] = []
            groups[country].append(name)
        
        return groups


# ==================== ProxyGroupGenerator ====================

class ProxyGroupGenerator:
    """Generate proxy-groups config"""
    
    # Country group display order
    COUNTRY_ORDER = [
        'ğŸ‡­ğŸ‡° é¦™æ¸¯', 'ğŸ‡¹ğŸ‡¼ å°æ¹¾', 'ğŸ‡¯ğŸ‡µ æ—¥æœ¬', 'ğŸ‡¸ğŸ‡¬ æ–°åŠ å¡', 'ğŸ‡ºğŸ‡¸ ç¾å›½',
        'ğŸ‡°ğŸ‡· éŸ©å›½', 'ğŸ‡¬ğŸ‡§ è‹±å›½', 'ğŸ‡©ğŸ‡ª å¾·å›½', 'ğŸ‡¨ğŸ‡¦ åŠ æ‹¿å¤§', 'ğŸ‡¦ğŸ‡º æ¾³å¤§åˆ©äºš',
        'ğŸ‡«ğŸ‡· æ³•å›½', 'ğŸ‡·ğŸ‡º ä¿„ç½—æ–¯', 'ğŸ‡®ğŸ‡³ å°åº¦', 'ğŸ‡³ğŸ‡± è·å…°', 'ğŸ‡¹ğŸ‡· åœŸè€³å…¶',
        'ğŸ‡¦ğŸ‡¶ å—ææ´²', 'ğŸ‡²ğŸ‡¾ é©¬æ¥è¥¿äºš', 'ğŸ‡ªğŸ‡¸ è¥¿ç­ç‰™', 'ğŸ‡»ğŸ‡³ è¶Šå—', 
        'ğŸ‡ºğŸ‡¦ ä¹Œå…‹å…°', 'ğŸ‡²ğŸ‡© æ‘©å°”å¤šç“¦', 'ğŸ‡³ğŸ‡¬ å°¼æ—¥åˆ©äºš', 'ğŸ”° å…¶ä»–'
    ]
    
    @staticmethod
    def generate_groups(proxies: List[dict], country_groups: Dict[str, List[str]]) -> List[dict]:
        """Generate complete proxy-groups config"""
        all_proxy_names = [p['name'] for p in proxies]
        groups = []
        
        # Sort country groups by node count (descending)
        sorted_countries = sorted(
            [c for c in country_groups.keys() if country_groups[c]],
            key=lambda c: len(country_groups[c]),
            reverse=True
        )
        
        # 1. GLOBAL (select) - includes DIRECT, REJECT, manual select, auto select, fallback, and country groups
        global_group = {
            'name': 'GLOBAL',
            'type': 'select',
            'proxies': ['DIRECT', 'REJECT', 'ğŸš€ æ‰‹åŠ¨é€‰æ‹©', 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©(æµ‹é€Ÿ)', 'ğŸ”¯ æ•…éšœè½¬ç§»'] + sorted_countries
        }
        groups.append(global_group)
        
        # 2. ğŸš€ Manual Select (select) - includes DIRECT, REJECT, and country groups
        node_select = {
            'name': 'ğŸš€ æ‰‹åŠ¨é€‰æ‹©',
            'type': 'select',
            'proxies': ['DIRECT', 'REJECT'] + sorted_countries
        }
        groups.append(node_select)
        
        # 3. â™»ï¸ Auto Select with speed test (url-test) - includes country groups
        auto_select = {
            'name': 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©(æµ‹é€Ÿ)',
            'type': 'url-test',
            'proxies': sorted_countries,
            'url': 'http://www.gstatic.com/generate_204',
            'interval': 300,
            'tolerance': 50
        }
        groups.append(auto_select)
        
        # 4. ğŸ”¯ Fallback (fallback) - includes country groups
        fallback = {
            'name': 'ğŸ”¯ æ•…éšœè½¬ç§»',
            'type': 'fallback',
            'proxies': sorted_countries,
            'url': 'http://www.gstatic.com/generate_204',
            'interval': 300
        }
        groups.append(fallback)
        
        # 5. Country/Region groups (select) - one group per country, sorted by node count
        for country in sorted_countries:
            if country in country_groups and country_groups[country]:
                country_group = {
                    'name': country,
                    'type': 'select',
                    'proxies': country_groups[country]
                }
                groups.append(country_group)
        
        return groups


# ==================== ConfigMerger ====================

class ConfigMerger:
    """Config merger main class"""
    
    # Source file config (in yaml folder)
    SOURCE_DIR = 'yaml'
    SOURCE_FILES = [
        ('å®å¯æ¢¦.yaml', 'å®å¯æ¢¦'),
        ('æµé‡å…‰æœºåœº.yaml', 'æµé‡å…‰æœºåœº'),
        ('æ·˜æ°”å…”.yaml', 'æ·˜æ°”å…”'),
        ('é£è§è§å…¬ç›Šæœºåœº.yaml', 'é£è§è§'),
        ('é­”æˆ’.yaml', 'é­”æˆ’')
    ]
    
    # ==================== Hardcoded Template Content ====================
    
    TEMPLATES = {
        'header': r"""mixed-port: 7890
allow-lan: true
bind-address: 0.0.0.0
mode: rule
log-level: info
external-controller: 127.0.0.1:9090
unified-delay: true
tcp-concurrent: true
find-process-mode: strict
keep-alive-interval: 15
profile:
  store-selected: true
  store-fake-ip: true
geodata-mode: true
geo-auto-update: true
geo-update-interval: 24
geox-url:
  geoip: "https://raw.githubusercontent.com/Loyalsoldier/geoip/release/geoip.dat"
  geosite: "https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/geosite.dat"

dns:
  enable: true
  prefer-h3: true
  listen: 0.0.0.0:1053
  ipv6: true
  default-nameserver:
    - 1.1.1.1
    - 8.8.8.8
  enhanced-mode: fake-ip
  fake-ip-range: 198.18.0.1/16
  fake-ip-filter:
    - "+.lan"
    - "+.local"
    - "geosite:private"
  nameserver:
    - https://cloudflare-dns.com/dns-query
    - https://dns.google/dns-query
  proxy-server-nameserver:
    - https://cloudflare-dns.com/dns-query
    - https://dns.google/dns-query
  fallback:
    - https://cloudflare-dns.com/dns-query
    - https://dns.google/dns-query
  nameserver-policy:
    "geosite:cn,private":
      - https://doh.pub/dns-query
      - https://dns.alidns.com/dns-query
sniffer:
  enable: true
  force-dns-mapping: true
  parse-pure-ip: true
  override-destination: false
  sniff:
    HTTP:
      ports: [80, 8080-8880, 10000]
      override-destination: true
    TLS:
      ports: [443, 8443]
    QUIC:
      ports: [443, 8443]
      override-destination: true
  skip-domain:
    - "*.apple.com"
    - "*.icloud.com"
    - "*.mzstatic.com"
    - "*.testflight.apple.com"
tun:
  enable: false
  stack: system
  auto-route: true
  auto-detect-interface: true
  dns-hijack:
    - any:53
""",
        'suffix': r"""rules:
  - RULE-SET, Apple, DIRECT
  - RULE-SET, Google, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, Microsoft, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, Github, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, HBO, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, Disney, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, TikTok, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, Netflix, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, GlobalMedia, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, Telegram, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, OpenAI, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, Gemini, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, Copilot, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, Claude, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, Crypto, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, Cryptocurrency, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, Game, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - RULE-SET, ChinaMax, DIRECT
  - RULE-SET, Lan, DIRECT
  - GEOIP, CN, DIRECT
  - RULE-SET, Global, ğŸš€ æ‰‹åŠ¨é€‰æ‹©
  - MATCH, GLOBAL

rule-providers:
  Apple:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Apple/Apple_Classical_No_Resolve.yaml
    interval: 86400
  Google:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Google/Google_No_Resolve.yaml
    interval: 86400
  Microsoft:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Microsoft/Microsoft.yaml
    interval: 86400
  Github:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/GitHub/GitHub.yaml
    interval: 86400
  HBO:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/HBO/HBO.yaml
    interval: 86400
  Disney:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Disney/Disney.yaml
    interval: 86400
  TikTok:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/TikTok/TikTok.yaml
    interval: 86400
  Netflix:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Netflix/Netflix.yaml
    interval: 86400
  GlobalMedia:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/GlobalMedia/GlobalMedia_Classical_No_Resolve.yaml
    interval: 86400
  Telegram:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Telegram/Telegram_No_Resolve.yaml
    interval: 86400
  OpenAI:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/OpenAI/OpenAI.yaml
    interval: 86400
  Gemini:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Gemini/Gemini.yaml
    interval: 86400
  Copilot:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Copilot/Copilot.yaml
    interval: 86400
  Claude:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Claude/Claude.yaml
    interval: 86400
  Crypto:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Crypto/Crypto.yaml
    interval: 86400
  Cryptocurrency:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Cryptocurrency/Cryptocurrency.yaml
    interval: 86400
  Game:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Game/Game.yaml
    interval: 86400
  Global:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Global/Global_Classical_No_Resolve.yaml
    interval: 86400
  ChinaMax:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/ChinaMax/ChinaMax_Classical_No_Resolve.yaml
    interval: 86400
  Lan:
    type: http
    behavior: classical
    format: yaml
    url: https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Lan/Lan.yaml
    interval: 86400

url-rewrite:
  - ^https?:\/\/(www.)?g\.cn https://www.google.com 302
  - ^https?:\/\/(www.)?google\.cn https://www.google.com 302
"""
    }

    def __init__(self, yaml_dir: str, output_file: str, custom_header: str = None, custom_suffix: str = None, file_aliases: Dict[str, str] = None):
        self.yaml_dir = yaml_dir
        self.output_file = output_file
        self.all_proxies: List[dict] = []
        self.header = custom_header if custom_header is not None else self.TEMPLATES['header']
        self.suffix = custom_suffix if custom_suffix is not None else self.TEMPLATES['suffix']
        self.file_aliases = file_aliases or {}

    @staticmethod
    def parse_template(content: str) -> dict:
        """Parse external template content, return header, suffix"""
        lines = content.splitlines(keepends=True)
        header_lines = []
        suffix_lines = []
        
        # Simple state machine:
        # 0: Header (before proxies/proxy-groups)
        # 1: Body (proxies/proxy-groups - ignored)
        # 2: Suffix (after proxy-groups, usually rules)
        
        # Simpler strategy: find proxies:, everything before is header
        # Find rules:, everything after is suffix (including rules)
        
        # Note: sometimes there are other things between proxies and rules.
        # Strategy here:
        # Header = start -> "proxies:"
        # Suffix = "rules:" -> end
        
        # If these keywords are not found, try best to split
        
        header_end_idx = -1
        suffix_start_idx = -1
        
        for i, line in enumerate(lines):
            stripped = line.strip()
            if stripped.startswith('proxies:'):
                header_end_idx = i
            elif stripped.startswith('rules:'):
                suffix_start_idx = i
                break
        
        if header_end_idx == -1:
             # Fallback: everything is header if no proxies defined
             return {'header': content, 'suffix': ''}
        
        header_content = "".join(lines[:header_end_idx]).rstrip()
        
        if suffix_start_idx != -1:
            suffix_content = "".join(lines[suffix_start_idx:])
        else:
            suffix_content = ""
            
        return {'header': header_content, 'suffix': suffix_content}
    
    @staticmethod
    def load_yaml(file_path: str) -> Optional[dict]:
        """Safely load YAML file"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            print(f"Warning: File not found - {file_path}")
            return None
        except yaml.YAMLError as e:
            print(f"Warning: YAML parse error - {file_path}: {e}")
            return None
        except Exception as e:
            print(f"Warning: Failed to read file - {file_path}: {e}")
            return None
    
    def load_source_proxies(self) -> List[dict]:
        """Load proxy nodes from all source files"""
        all_proxies = []
        
        if not os.path.exists(self.yaml_dir):
            print(f"Error: Directory {self.yaml_dir} does not exist")
            return []
            
        files = [f for f in os.listdir(self.yaml_dir) if f.endswith('.yaml') or f.endswith('.yml')]
        
        # Exclude output file and template file
        excludes = ['myconfig.yaml', 'myconfig_template.yaml']
        
        # Sort completely by file_aliases order (if available)
        def sort_key(filename):
            if self.file_aliases:
                alias_keys = list(self.file_aliases.keys())
                if filename in alias_keys:
                    return (0, alias_keys.index(filename))
            return (1, filename)  # Files not in file_aliases sorted by filename at the end
        
        files = sorted(files, key=sort_key)
        
        for file_name in files:
            if file_name in excludes:
                continue
                
            file_path = os.path.join(self.yaml_dir, file_name)
            
            # Determine source name (prefix)
            default_name = os.path.splitext(file_name)[0]
            # Use alias if provided, otherwise default
            source_name = self.file_aliases.get(file_name, default_name)
            
            print(f"Processing: {file_name}...")
            
            # Use enhanced parser to load config (supports YAML, Base64, Vmess links)
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                config = SubscriptionParser.parse_content(content)
            except Exception as e:
                print(f"Warning: Cannot parse file {file_name}: {e}")
                continue
            
            if not config or not isinstance(config, dict):
                print(f"Warning: {file_name} has no valid content after parsing, skipped.")
                continue
            
            proxies = config.get('proxies', [])
            if not proxies:
                print(f"Info: {file_name} has no proxy nodes")
                continue
            
            # Filter invalid nodes (basic filter)
            valid_proxies = ProxyFilter.filter_proxies(proxies)
            
            # Filter junk nodes (keyword filter)
            ignore_keywords = [
                "å‰©ä½™æµé‡", "åˆ°æœŸ", "é‡ç½®", "å®˜ç½‘", "å»ºè®®", "è¿‡æ»¤æ‰", 
                "æœªåˆ°æœŸ", "æ— æ•ˆ", "æµ‹è¯•", "é‚®ä»¶", "è”ç³»", 
                "ç¾¤", "é¢‘é“", "æ›´æ–°", "å‘å¸ƒ", "APP", "æ•™ç¨‹", "æ— æ³•"
            ]
            
            clean_proxies = []
            for p in valid_proxies:
                name = str(p.get('name', ''))
                if any(k in name for k in ignore_keywords):
                    # print(f"  - Skipping invalid node: {name}") 
                    continue
                clean_proxies.append(p)
                
            print(f"Info: {file_name} - Original: {len(proxies)}, Basic filter: {len(valid_proxies)}, Final valid: {len(clean_proxies)}")
            
            # Add source prefix
            transformed_proxies = NameTransformer.transform_proxies(clean_proxies, source_name)
            all_proxies.extend(transformed_proxies)
        
        return all_proxies
    
    def merge_and_generate(self) -> dict:
        """Merge nodes and generate final config"""
        # Load all source proxies
        self.all_proxies = self.load_source_proxies()
        print(f"\nTotal valid proxy nodes: {len(self.all_proxies)}")
        
        if not self.all_proxies:
            print("Warning: No valid proxy nodes found")
            return {'proxies': [], 'proxy-groups': []}
        
        # Group by country
        country_groups = CountryGrouper.group_by_country(self.all_proxies)
        print(f"Country/Region groups: {len(country_groups)}")
        for country, nodes in country_groups.items():
            print(f"  {country}: {len(nodes)} nodes")
        
        # Generate proxy groups
        proxy_groups = ProxyGroupGenerator.generate_groups(self.all_proxies, country_groups)
        
        return {
            'proxies': self.all_proxies,
            'proxy-groups': proxy_groups
        }
    
    def save(self, config: dict):
        """Save config to file (maintain original format style: Basic -> Proxies -> Groups -> Rules -> Providers -> Others)"""
        import json
        
        # Get dynamically generated parts
        proxies = config.get('proxies', [])
        proxy_groups = config.get('proxy-groups', [])
        
        with open(self.output_file, 'w', encoding='utf-8') as f:
            # 1. Write Basic config (hardcoded header)
            f.write(self.header)
            
            # 2. Write Proxies
            f.write('\nproxies:\n')
            for proxy in proxies:
                proxy_json = json.dumps(proxy, ensure_ascii=False, separators=(',', ':'))
                f.write(f'  - {proxy_json}\n')
            
            # 3. Write Proxy Groups
            f.write('\nproxy-groups:\n')
            for group in proxy_groups:
                group_json = json.dumps(group, ensure_ascii=False, separators=(',', ':'))
                f.write(f'  - {group_json}\n')

            # 4. Write Suffix (Rules, Providers, Url-Rewrite)
            f.write('\n' + self.suffix)
        
        print(f"\nConfig saved to: {self.output_file}")


# ==================== Main Entry ====================


if __name__ == '__main__':
    # Config directory and file paths (relative to script location)
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    # Source files in uploads subdirectory
    SOURCE_DIR = os.path.join(BASE_DIR, 'uploads')
    OUTPUT_FILE = os.path.join(BASE_DIR, 'myconfig.yaml')
    
    # Ensure source directory exists
    if not os.path.exists(SOURCE_DIR):
        print(f"Error: Source directory {SOURCE_DIR} does not exist")
        sys.exit(1)
        
    print("Starting Clash config merge...")
    merger = ConfigMerger(SOURCE_DIR, OUTPUT_FILE)
    config = merger.merge_and_generate()
    merger.save(config)
    
    print("=" * 50)
    print("Merge completed!")

